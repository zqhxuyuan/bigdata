package com.chinahadoop.streamming

import com.td.bigdata.spark.intro.SparkUtil
import org.apache.spark.SparkContext._
import org.apache.spark.storage.StorageLevel
import org.apache.spark.streaming._
import org.apache.spark.streaming.StreamingContext._

/**
 * Chen Chao
 */

object WindowCounter {
  def main(args: Array[String]) {
    if (args.length < 4) {
      System.err.println("Usage: NetworkWordCount <master> <hostname> <port> <interval> " +
        "<windowLength> <slideInterval>\n" +
        "In local mode, <master> should be 'local[n]' with n > 1")
      System.exit(1)
    }

    StreamingExamples.setStreamingLogLevels()

    // Create the context with a 1 second batch size
    //val ssc = new StreamingContext(args(0), "WindowCounter", Seconds(args(3).toInt), System.getenv("SPARK_HOME"), StreamingContext.jarOfClass(this.getClass))
    val ssc = SparkUtil.getStreamContext()

    ssc.checkpoint(".")
    // Create a NetworkInputDStream on target ip:port and count the
    // words in input stream of \n delimited text (eg. generated by 'nc')
    val lines = ssc.socketTextStream(args(1), args(2).toInt, StorageLevel.MEMORY_ONLY_SER)
    val words = lines.flatMap(_.split(" "))

    //val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow((x : Int, y : Int) => x + y, Seconds(args(4)), Seconds(args(5)))
    val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow(_+_, _-_,Seconds(args(4).toInt), Seconds(args(5).toInt))


    //val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow(_+_, Seconds(30))
    //val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow((x : Int, y : Int) => x + y,_-_, Seconds(6), Seconds(6))
    //val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow(_+_, _-_, Seconds(6), Seconds(6))
    //val wordCounts = words.map(x => (x , 1)).reduceByKey(_+_)
    //val wordCounts = words.map(x => (x , 1)).countByValueAndWindow(Seconds(12),Seconds(6))

    //val wordCounts = words.map(x => (x , 1)).reduceByKeyAndWindow(_+_, Seconds(30),Seconds(12)) cannot do this

    val sortedWordCount = wordCounts.map{case (char,count) => (count,char)}.transform(_.sortByKey(false))
      .map{case (char,count) => (count,char)}

    //wordCounts.print()
    sortedWordCount.print()
    ssc.start()
    ssc.awaitTermination()
  }
}
